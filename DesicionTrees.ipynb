{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bd0516e7cb654f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Exercise 2: Decision Trees\n",
    "\n",
    "In this assignment you will implement a Decision Tree algorithm as learned in class.\n",
    "\n",
    "## Read the following instructions carefully:\n",
    "\n",
    "1. This jupyter notebook contains all the step by step instructions needed for this exercise.\n",
    "1. Submission includes this notebook only with the exercise number and your ID as the filename. For example: `hw2_123456789_987654321.ipynb` if you submitted in pairs and `hw2_123456789.ipynb` if you submitted the exercise alone.\n",
    "1. Write **efficient vectorized** code whenever possible. Some calculations in this exercise take several minutes when implemented efficiently, and might take much longer otherwise. Unnecessary loops will result in point deduction.\n",
    "1. You are responsible for the correctness of your code and should add as many tests as you see fit. Tests will not be graded nor checked.\n",
    "1. Write your functions in this notebook only. **Do not create Python modules and import them**.\n",
    "1. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/) and [numpy](https://www.numpy.org/devdocs/reference/) only. **Do not import anything else.**\n",
    "1. Your code must run without errors. Make sure your `numpy` version is at least 1.15.4 and that you are using at least python 3.6. Changes of the configuration we provided are at your own risk. Any code that cannot run will not be graded.\n",
    "1. Write your own code. Cheating will not be tolerated.\n",
    "1. Answers to qualitative questions should be written in **markdown** cells (with $\\LaTeX$ support). Answers that will be written in commented code blocks will not be checked.\n",
    "\n",
    "## In this exercise you will perform the following:\n",
    "1. Practice OOP in python.\n",
    "2. Implement two impurity measures: Gini and Entropy.\n",
    "3. Construct a decision tree algorithm.\n",
    "4. Prune the tree to achieve better results.\n",
    "5. Visualize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I have read and understood the instructions: *** YOUR ID HERE ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ed9fe7b1026e33cb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make matplotlib figures appear inline in the notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c6ac605270c2b091",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Warmup - OOP in python\n",
    "\n",
    "Our desicion tree will be implemented using a dedicated python class. Python classes are very similar to classes in Java.\n",
    "\n",
    "\n",
    "You can use the following [site](https://jeffknupp.com/blog/2014/06/18/improve-your-python-python-classes-and-object-oriented-programming/) to learn about classes in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, node):\n",
    "        self.children.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Node at 0x1d2a4b675e0>, <__main__.Node at 0x1d2a4b67790>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = Node(5)\n",
    "p = Node(6)\n",
    "q = Node(7)\n",
    "n.add_child(p)\n",
    "n.add_child(q)\n",
    "n.children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2f1ceb251c649b62",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "For the following exercise, we will use a dataset containing mushroom data `agaricus-lepiota.csv`. \n",
    "\n",
    "This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family. Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous\n",
    "one (=there are only two classes **edible** and **poisonous**). \n",
    "    \n",
    "The dataset contains 8124 observations with 22 features:\n",
    "1. cap-shape: bell=b,conical=c,convex=x,flat=f,knobbed=k,sunken=s\n",
    "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "4. bruises: bruises=t,no=f\n",
    "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
    "6. gill-attachment: attached=a,descending=d,free=f,notched=n\n",
    "7. gill-spacing: close=c,crowded=w,distant=d\n",
    "8. gill-size: broad=b,narrow=n\n",
    "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g,green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "10. stalk-shape: enlarging=e,tapering=t\n",
    "11. stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r\n",
    "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "16. veil-type: partial=p,universal=u\n",
    "17. veil-color: brown=n,orange=o,white=w,yellow=y\n",
    "18. ring-number: none=n,one=o,two=t\n",
    "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n",
    "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n",
    "21. population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
    "22. habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d\n",
    "\n",
    "First, we will read and explore the data using pandas and the `.read_csv` method. Pandas is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d79cb4542926ad3f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('agaricus-lepiota.csv')\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>...</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3656</td>\n",
       "      <td>3244</td>\n",
       "      <td>2284</td>\n",
       "      <td>4748</td>\n",
       "      <td>3528</td>\n",
       "      <td>7914</td>\n",
       "      <td>6812</td>\n",
       "      <td>5612</td>\n",
       "      <td>1728</td>\n",
       "      <td>4608</td>\n",
       "      <td>...</td>\n",
       "      <td>4464</td>\n",
       "      <td>4384</td>\n",
       "      <td>8124</td>\n",
       "      <td>7924</td>\n",
       "      <td>7488</td>\n",
       "      <td>3968</td>\n",
       "      <td>2388</td>\n",
       "      <td>4040</td>\n",
       "      <td>3148</td>\n",
       "      <td>4182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cap-shape cap-surface cap-color bruises  odor gill-attachment  \\\n",
       "count       8124        8124      8124    8124  8124            8124   \n",
       "unique         6           4        10       2     9               2   \n",
       "top            x           y         n       f     n               f   \n",
       "freq        3656        3244      2284    4748  3528            7914   \n",
       "\n",
       "       gill-spacing gill-size gill-color stalk-shape  ...  \\\n",
       "count          8124      8124       8124        8124  ...   \n",
       "unique            2         2         12           2  ...   \n",
       "top               c         b          b           t  ...   \n",
       "freq           6812      5612       1728        4608  ...   \n",
       "\n",
       "       stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "count                    8124                   8124      8124       8124   \n",
       "unique                      9                      9         1          4   \n",
       "top                         w                      w         p          w   \n",
       "freq                     4464                   4384      8124       7924   \n",
       "\n",
       "       ring-number ring-type spore-print-color population habitat class  \n",
       "count         8124      8124              8124       8124    8124  8124  \n",
       "unique           3         5                 9          6       7     2  \n",
       "top              o         p                 w          v       d     e  \n",
       "freq          7488      3968              2388       4040    3148  4182  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "[0.33333333 0.66666667 1.         1.33333333 1.66666667 2.        ]\n",
      "[1 1 1 1 1 1]\n",
      "[0.00308642 0.01234568 0.02777778 0.04938272 0.07716049 0.11111111]\n",
      "0.2808641975308642\n"
     ]
    }
   ],
   "source": [
    "#this block is for tests\n",
    "df = pd.DataFrame({'A': [1, 2, 3], \n",
    "                   'B': [1, 2, np.nan], \n",
    "                   'C': [4, 5, 6], \n",
    "                   'D': [np.nan, np.nan, np.nan]})\n",
    "missing_values = df.columns[df.isnull().any()].tolist() #crate a list of all the columns with missing values\n",
    "#B = df.copy\n",
    "#print(missing_values)\n",
    "for miss in missing_values:\n",
    "  df.drop(miss,inplace=True, axis=1)  #delete al the columns with missung values from df\n",
    "\n",
    "values, counts = np.unique(df, return_counts=True)\n",
    "Ssize = df.shape[0]\n",
    "print(values)\n",
    "values = values/3\n",
    "print(values)\n",
    "print(counts)\n",
    "SumSquerdPropability = np.square((values/6))\n",
    "print(SumSquerdPropability)\n",
    "print(sum(SumSquerdPropability))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of the Decision Tree algorithm is that almost no preprocessing is required. However, finding missing values is always required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Find columns with missing values and remove them from the data.#\n",
    "#############################################################################\n",
    "\n",
    "# Create a list of all the culomns in the data that have missing values\n",
    "MissingValueColumns = data.columns[data.isnull().any()].tolist()\n",
    "\n",
    "#remove all the culomns with missing values from data\n",
    "for column in MissingValueColumns:\n",
    "    data.drop(column ,inplace=True, axis=1)\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>...</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3656</td>\n",
       "      <td>3244</td>\n",
       "      <td>2284</td>\n",
       "      <td>4748</td>\n",
       "      <td>3528</td>\n",
       "      <td>7914</td>\n",
       "      <td>6812</td>\n",
       "      <td>5612</td>\n",
       "      <td>1728</td>\n",
       "      <td>4608</td>\n",
       "      <td>...</td>\n",
       "      <td>4464</td>\n",
       "      <td>4384</td>\n",
       "      <td>8124</td>\n",
       "      <td>7924</td>\n",
       "      <td>7488</td>\n",
       "      <td>3968</td>\n",
       "      <td>2388</td>\n",
       "      <td>4040</td>\n",
       "      <td>3148</td>\n",
       "      <td>4182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cap-shape cap-surface cap-color bruises  odor gill-attachment  \\\n",
       "count       8124        8124      8124    8124  8124            8124   \n",
       "unique         6           4        10       2     9               2   \n",
       "top            x           y         n       f     n               f   \n",
       "freq        3656        3244      2284    4748  3528            7914   \n",
       "\n",
       "       gill-spacing gill-size gill-color stalk-shape  ...  \\\n",
       "count          8124      8124       8124        8124  ...   \n",
       "unique            2         2         12           2  ...   \n",
       "top               c         b          b           t  ...   \n",
       "freq           6812      5612       1728        4608  ...   \n",
       "\n",
       "       stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "count                    8124                   8124      8124       8124   \n",
       "unique                      9                      9         1          4   \n",
       "top                         w                      w         p          w   \n",
       "freq                     4464                   4384      8124       7924   \n",
       "\n",
       "       ring-number ring-type spore-print-color population habitat class  \n",
       "count         8124      8124              8124       8124    8124  8124  \n",
       "unique           3         5                 9          6       7     2  \n",
       "top              o         p                 w          v       d     e  \n",
       "freq          7488      3968              2388       4040    3148  4182  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the dataset to `Training` and `Testing` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape:  (6093, 22)\n",
      "Testing dataset shape:  (2031, 22)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Making sure the last column will hold the labels\n",
    "X, y = data.drop('class', axis=1), data['class']\n",
    "X = np.column_stack([X,y])\n",
    "# split dataset using random_state to get the same split each time\n",
    "X_train, X_test = train_test_split(X, random_state=99)\n",
    "\n",
    "print(\"Training dataset shape: \", X_train.shape)\n",
    "print(\"Testing dataset shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fd7b0191f3f1e897",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Impurity Measures\n",
    "\n",
    "Impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. Implement the functions `calc_gini` and `calc_entropy`. You are encouraged to test your implementation (10 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(data):\n",
    "    \"\"\"\n",
    "    Calculate gini impurity measure of a dataset.\n",
    " \n",
    "    Input:\n",
    "    - data: any dataset where the last column holds the labels.\n",
    " \n",
    "    Returns the gini impurity.    \n",
    "    \"\"\"\n",
    "    gini = 0.0\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    #Ssize = the numbers of elements in the data \n",
    "    Labelscolumn = data[:,data.shape[1] -1]\n",
    "    Ssize = data.shape[0]\n",
    "    #print(Ssize)\n",
    "    \n",
    "    #The uniqe function return 2 values \n",
    "    #SI is an array that has the all the differnt values \"names\"\n",
    "    #SIsize is an array with the corespondig size of for each \"group\"(element) in SI \n",
    "    SI, SIsize = np.unique(Labelscolumn, return_counts=True)\n",
    "    #print(SIsize)\n",
    "\n",
    "    \n",
    "    #divide all the elemnt in SIsize with the constant Ssize\n",
    "    SIdevidebyS = SIsize/Ssize\n",
    "    \n",
    "    #return the sum of the squerd propabilitis of the elemnt in SI\n",
    "    SumSquerdPropability = sum(np.square(SIdevidebyS))\n",
    "    \n",
    "    #After we made the sum of (|SI|/|S|), the last part is: 1 - SumSquerdPropability \n",
    "    \n",
    "    gini = 1 - SumSquerdPropability \n",
    "    \n",
    "    \n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(data):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a dataset.\n",
    "\n",
    "    Input:\n",
    "    - data: any dataset where the last column holds the labels.\n",
    "\n",
    "    Returns the entropy of the dataset.    \n",
    "    \"\"\"\n",
    "    entropy = 0.0\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    #Ssize = the numbers of elements in the data \n",
    "    Labelscolumn = data[:,data.shape[1]-1]\n",
    "    Ssize = data.shape[0]\n",
    "    \n",
    "    #The uniqe function return 2 values \n",
    "    #SI is an array that have the all the differnt values \"names\"\n",
    "    #SIsize is an array with the corespondig size of for each \"group\"(element) in SI \n",
    "    SI, SIsize = np.unique(Labelscolumn, return_counts=True)\n",
    "    \n",
    "    \n",
    "    #divide all the elemnt in SIsize with the constant Ssize\n",
    "    SIdevidebyS = SIsize/Ssize\n",
    "    \n",
    "    #return an arry with log(|SI|\\|S|)\n",
    "    LogSIdevidebyS = (np.log2(SIdevidebyS))\n",
    "    \n",
    "    #entropy = -SUM((|SI|\\|S|)\\(log(|SI|\\|S|))\n",
    "    \n",
    "    entropy = (-1) * sum(np.multiply(SIdevidebyS,LogSIdevidebyS))\n",
    "    \n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4995636322379775, 0.9993703627906085)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Tests Here #####\n",
    "calc_gini(X), calc_entropy(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goodness of Split\n",
    "\n",
    "Given a feature the Goodnees of Split measures the reduction in the impurity if we split the data according to the feature.\n",
    "$$\n",
    "\\Delta\\varphi(S, A) = \\varphi(S) - \\sum_{v\\in Values(A)} \\frac{|S_v|}{|S|}\\varphi(S_v)\n",
    "$$\n",
    "\n",
    "In our implementation the goodness_of_split function will return either the Goodness of Split or the Gain Ratio as learned in class. You'll control the return value with the `gain_ratio` parameter. If this parameter will set to False (the default value) it will return the regular Goodness of Split. If it will set to True it will return the Gain Ratio.\n",
    "$$\n",
    "GainRatio(S,A)=\\frac{InformationGain(S,A)}{SplitInformation(S,A)}\n",
    "$$\n",
    "Where:\n",
    "$$\n",
    "InformationGain(S,A)=Goodness\\ of\\ Split\\ calculated\\ with\\ Entropy\\ as\\ the\\ Impurity\\ function \\\\\n",
    "SplitInformation(S,A)=- \\sum_{a\\in A} \\frac{|S_a|}{|S|}\\log\\frac{|S_a|}{|S|}\n",
    "$$\n",
    "NOTE: you can add more parameters to the function and you can also add more returning variables (The given parameters and the given returning variable should not be touch). (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodness_of_split(data, feature, impurity_func, gain_ratio=False):\n",
    "    \"\"\"\n",
    "    Calculate the goodness of split of a dataset given a feature and impurity function.\n",
    "\n",
    "    Input:\n",
    "    - data: any dataset where the last column holds the labels.\n",
    "    - feature: the feature index.\n",
    "    - impurity func: a function that calculates the impurity.\n",
    "    - gain_ratio: goodness of split or gain ratio flag.\n",
    "\n",
    "    Returns the goodness of split (or the Gain Ration).  \n",
    "    \"\"\"\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    #check for the correct impurity function to use\n",
    "    if gain_ratio:  \n",
    "        impurity_func = calc_entropy\n",
    "    \n",
    "    feature_column = data[:,feature] #the column of the feature\n",
    "    \n",
    "    #count the number of each uniqe value in the given feature culomn\n",
    "    unique_values, count = np.unique(feature_column, return_counts=True)\n",
    "    \n",
    "    total_instances = data.shape[0] #the size of S \n",
    "    \n",
    "    #create a vector of the impurity of each sub array after spliting\n",
    "    impurity_by_unique_values = [impurity_func(data[feature_column == value]) for value in unique_values]\n",
    "\n",
    "    # calculate the sum of the impurity of the children (we multipaly the count vectoer wite the impurity vector)\n",
    "    sum_children_impurity = np.sum(count * np.array(impurity_by_unique_values))/total_instances\n",
    "    goodness =  impurity_func(data) - sum_children_impurity\n",
    "    \n",
    "    if gain_ratio:\n",
    "        information_gain = goodness \n",
    "        feature_propabilities = count/total_instances\n",
    "        split_information = -np.sum(feature_propabilities * np.log2(feature_propabilities))\n",
    "        goodness = information_gain / split_information\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return goodness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Decision Tree\n",
    "\n",
    "Use a Python class to construct the decision tree. Your class should support the following functionality:\n",
    "\n",
    "1. Initiating a node for a decision tree. You will need to use several class methods and class attributes and you are free to use them as you see fit. We recommend that every node will hold the feature and value used for the split and its children.\n",
    "2. Your code should support both Gini and Entropy as impurity measures. \n",
    "3. The provided data includes categorical data. In this exercise, when splitting a node create the number of children needed according to the attribute unique values.\n",
    "\n",
    "Complete the class `DecisionNode`. The structure of this class is entirely up to you. \n",
    "\n",
    "Complete the function `build_tree`. This function should get the training dataset and the impurity as inputs, initiate a root for the decision tree and construct the tree according to the procedure you learned in class. (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    \"\"\"\n",
    "    This class will hold everything you require to construct a decision tree.\n",
    "    The structure of this class is up to you. However, you need to support basic \n",
    "    functionality as described above. It is highly recommended that you \n",
    "    first read and understand the entire exercise before diving into this class.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    - featue: the current feature the node has bin split by\n",
    "    - data: the data after being split by that same feature\n",
    "    - impurity: the impurity function given\n",
    "    - gain_ratio: goodness of split or gain ratio flag\n",
    "    - current_deapth: the current depth of the node\n",
    "    - children: list of children created when impurity is not 0 and \n",
    "    - value: the value at current feature of this specific node\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, data, feature, value, goodness, impurity, list_of_path_features, gain_ratio=False, current_depth=0):\n",
    "        self.feature = feature # the feature column index it will split by\n",
    "        self.data = data # the data given to the decision node after\n",
    "        self.goodness = goodness\n",
    "        self.impurity_func = impurity # impurity function to be used\n",
    "        self.gain_ratio = gain_ratio # boolean that defines if to return gain_ratio or goodness of split as split paramiter\n",
    "        self.children = [] # only filled when epxand_or_finnish is called\n",
    "        self.value = value # the value that was split by\n",
    "        self.current_depth = current_depth\n",
    "        self.impurity = self.impurity_func(self.data) # get impurity of current \n",
    "        self.list_of_path_features = list_of_path_features\n",
    "\n",
    "        #implamnted for prediction\n",
    "        self.pred = self.get_favored_label_value()\n",
    "\n",
    "    def add_child(self, Dec_node):\n",
    "        self.children.append(Dec_node)\n",
    "\n",
    "    def get_favored_label_value(self): # returns favored label value\n",
    "        current_label_data = self.data[:,(self.data.shape[1]-1)] # get label column from current_data\n",
    "        unique, pos = np.unique(current_label_data, return_inverse = True)\n",
    "        counts = np.bincount(pos)\n",
    "        maxpos = counts.argmax()\n",
    "        return(unique[maxpos])\n",
    "\n",
    "\n",
    "    def count_children(self):\n",
    "        if len(self.children) == 0: \n",
    "            return 1\n",
    "        else:\n",
    "            return 1 + sum([child.count_children() for child in self.children])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"I am a node at {self.current_depth} depth, my goodness is {self.goodness} , my value is {self.value} and I am split on feature {self.feature}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_current_best_feature(data, impurity_func, list_of_used_features ,gain_ratio=False): # returns feature index with best goodnes_of split based on current data and list_of_path-features \n",
    "    count = 0\n",
    "    best_spliting_feature, max_goodness = -1, -1\n",
    "    for value in list_of_used_features:\n",
    "        if value == False:\n",
    "            temp_goodness = goodness_of_split(data, count, impurity_func, gain_ratio)\n",
    "            if temp_goodness > max_goodness:\n",
    "                max_goodness = temp_goodness\n",
    "                best_spliting_feature = count\n",
    "        count +=1\n",
    "    return best_spliting_feature, max_goodness\n",
    "    \n",
    "def get_values_by_feature(data, feature): # returns list unique of values by feature index on data\n",
    "    return np.unique(data[:,feature])\n",
    "    \n",
    "def get_data_by_feature_value(data, feature, value): # returns data where on column feature every row is equal to value\n",
    "    sub_data = data[data[:,feature] == value]\n",
    "    return sub_data\n",
    "    \n",
    "\n",
    "def build_tree(data, impurity, gain_ratio=False, min_samples_split=1, max_depth=1000):\n",
    "    \"\"\"\n",
    "    Build a tree using the given impurity measure and training dataset. \n",
    "    You are required to fully grow the tree until all leaves are pure. \n",
    "\n",
    "    Input:\n",
    "    - data: the training dataset.\n",
    "    - impurity: the chosen impurity measure. Notice that you can send a function\n",
    "                as an argument in python.\n",
    "    - gain_ratio: goodness of split or gain ratio flag\n",
    "    - min_samples_split: the minimum number of samples required to split an internal node\n",
    "    - max_depth: the allowable depth of the tree\n",
    "\n",
    "    Output: the root node of the tree.\n",
    "    \"\"\"\n",
    "\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    \n",
    "    list_of_path_features = [False for x in range(0,data.shape[1]-1) ] # create a list of feature indecease where the path to current node was to not check twice\n",
    "    first_feature, first_goodness = get_current_best_feature(data, impurity, list_of_path_features) # get feature for root\n",
    "    root = DecisionNode(data, first_feature, None, first_goodness, impurity, list_of_path_features ) # NODE CREATION HERE\n",
    "    queue = [root]\n",
    "    while len(queue) > 0:\n",
    "        current_node = queue.pop(0) # pop first node\n",
    "        current_node.list_of_path_features[current_node.feature] = True\n",
    "        \n",
    "        \n",
    "        # check parmiters for leaf: data > min-sample_split, more than only one split value, depth < max_depth and current_node.goodness > 0\n",
    "        if current_node.data.shape[0] > min_samples_split  and current_node.goodness > 0 and current_node.current_depth < max_depth:\n",
    "            # after check this is not a leaf\n",
    "            # update list_of_path_features\n",
    "            current_values = get_values_by_feature(current_node.data, current_node.feature)\n",
    "            if len(current_values) !=1:\n",
    "                for value in current_values:\n",
    "                    updated_feature_path = current_node.list_of_path_features.copy()\n",
    "                    sub_data = get_data_by_feature_value(current_node.data, current_node.feature, value) # sub data where all rows are value at feature\n",
    "                    sub_feature, sub_goodness = get_current_best_feature(sub_data, impurity, current_node.list_of_path_features, gain_ratio) # get best feature for current sub_data\n",
    "                    sub_node = DecisionNode(sub_data, sub_feature, value, sub_goodness, impurity, updated_feature_path, gain_ratio, (current_node.current_depth + 1))\n",
    "                    current_node.add_child(sub_node)\n",
    "                    queue.append(sub_node)\n",
    "                \n",
    "            # split data, find best features for sub data, create nodes by that feature and data and add to queue and children list of current_node\n",
    "        #print(current_node)\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python supports passing a function as an argument to another function.\n",
    "tree_gini = build_tree(data=X_train, impurity=calc_gini) # gini and goodness of split\n",
    "tree_entropy = build_tree(data=X_train, impurity=calc_entropy) # entropy and goodness of split\n",
    "tree_entropy_gain_ratio = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True) # entropy and gain ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231\n",
      "3227\n",
      "2447\n"
     ]
    }
   ],
   "source": [
    "print(tree_gini.count_children())\n",
    "print(tree_entropy.count_children())\n",
    "print(tree_entropy_gain_ratio.count_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "test_tree = build_tree(X_train, calc_gini, min_samples_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree evaluation\n",
    "\n",
    "Complete the functions `predict` and `calc_accuracy`. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, instance):\n",
    "    \"\"\"\n",
    "    Predict a given instance using the decision tree\n",
    " \n",
    "    Input:\n",
    "    - root: the root of the decision tree.\n",
    "    - instance: an row vector from the dataset. Note that the last element \n",
    "                of this vector is the label of the instance.\n",
    " \n",
    "    Output: the prediction of the instance.\n",
    "    \"\"\"\n",
    "    pred = None\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    while len(node.children) > 0:\n",
    "        for child_node in node.children: # iterate over all children to find matching child in path\n",
    "            given_value = instance[node.feature] # the value of the feature in the current row\n",
    "            node_value = child_node.value # the value of the child\n",
    "            if given_value == node_value: # each instance is a 1dim np.array\n",
    "                node = child_node # change pointer to next node in path\n",
    "                break\n",
    "        else:\n",
    "            break           \n",
    "                \n",
    "\n",
    "    \n",
    "\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return node.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(node, dataset):\n",
    "    \"\"\"\n",
    "    Predict a given dataset using the decision tree\n",
    " \n",
    "    Input:\n",
    "    - node: a node in the decision tree.\n",
    "    - dataset: the dataset on which the accuracy is evaluated\n",
    "\n",
    "    Output: the accuracy of the decision tree on the given dataset (%).\n",
    "    \"\"\"\n",
    "    accuracy = 0\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    #to caclculate accuracy we need to find how much instances we need to find true A true B false A and false B\n",
    "    #the accuracy will be (true_A +true_B)/(true_A + true_B + false_A + false_B) = true / all\n",
    "    true_predictions = 0\n",
    "    number_of_instances = dataset.shape[0]\n",
    "    \n",
    "    \n",
    "    #calculate the predict value for every instance in the data set\n",
    "    for instance in dataset:\n",
    "        #if the prediction == real label we need to add 1 to the true_prediction counter\n",
    "        if predict(node,instance) == instance[-1]:\n",
    "            true_predictions  += 1 # add one to correct prediction\n",
    "        \n",
    "        \n",
    "    \n",
    "    accuracy = true_predictions/ number_of_instances\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9161332676842278"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(test_tree, X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the three trees using the training set, you should calculate the accuracy on the test set. For each tree print the training and test accuracy. Select the tree that gave you the best test accuracy. For the rest of the exercise, use that tree (when you asked to build another tree use the same impurity function and same gain_ratio flag). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_gini accuracy statistics:\n",
      "\n",
      "X_train accuracy: 0.9924503528639422\n",
      "X_test accuracy: 0.7749876907927129\n",
      "\n",
      "\n",
      "tree_entropy accuracy statistics:\n",
      "\n",
      "X_train accuracy: 0.9940915805022157\n",
      "X_test accuracy: 0.7725258493353028\n",
      "\n",
      "\n",
      "tree_entropy_gain_ratio accuracy statistics:\n",
      "\n",
      "X_train accuracy: 0.971278516330215\n",
      "X_test accuracy: 0.8079763663220089\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Your code here ####\n",
    "tree_gini_test_accuricy = calc_accuracy(tree_gini, X_test)\n",
    "tree_gini_train_accuricy = calc_accuracy(tree_gini, X_train)\n",
    "\n",
    "print(\"tree_gini accuracy statistics:\")\n",
    "print()\n",
    "print(f\"X_train accuracy: {tree_gini_train_accuricy}\")\n",
    "print(f\"X_test accuracy: {tree_gini_test_accuricy}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "tree_entropy_test_accuricy = calc_accuracy(tree_entropy, X_test)\n",
    "tree_entropy_train_accuricy = calc_accuracy(tree_entropy, X_train)\n",
    "\n",
    "print(\"tree_entropy accuracy statistics:\")\n",
    "print()\n",
    "print(f\"X_train accuracy: {tree_entropy_train_accuricy}\")\n",
    "print(f\"X_test accuracy: {tree_entropy_test_accuricy}\")\n",
    "print()\n",
    "print()\n",
    "\n",
    "tree_entropy_gain_ratio_test_accuricy = calc_accuracy(tree_entropy_gain_ratio, X_test)\n",
    "tree_entropy_gain_ratio_train_accuricy = calc_accuracy(tree_entropy_gain_ratio, X_train)\n",
    "\n",
    "print(\"tree_entropy_gain_ratio accuracy statistics:\")\n",
    "print()\n",
    "print(f\"X_train accuracy: {tree_entropy_gain_ratio_train_accuricy}\")\n",
    "print(f\"X_test accuracy: {tree_entropy_gain_ratio_test_accuricy}\")\n",
    "print()\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth pruning\n",
    "\n",
    "(15 points)\n",
    "\n",
    "Consider the following max_depth values: [1, 2, 3, 4, 5, 6, 7, 8]. For each value, construct a tree and prune it according to the max_depth value = don't let the tree to grow beyond this depth. Next, calculate the training and testing accuracy.<br>\n",
    "On a single plot, draw the training and testing accuracy as a function of the max_depth. Mark the best result on the graph with red circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for max depth = 1 the train_accuracy = 0.8885606433612342 and the test_accuracy = 0.8852781880846874\n",
      "\n",
      "for max depth = 2 the train_accuracy = 0.8885606433612342 and the test_accuracy = 0.8852781880846874\n",
      "\n",
      "for max depth = 3 the train_accuracy = 0.8964385360249466 and the test_accuracy = 0.8931560807483998\n",
      "\n",
      "for max depth = 4 the train_accuracy = 0.901854587231249 and the test_accuracy = 0.8956179222058099\n",
      "\n",
      "for max depth = 5 the train_accuracy = 0.9026752010503857 and the test_accuracy = 0.8902018709995076\n",
      "\n",
      "for max depth = 6 the train_accuracy = 0.9056294107992778 and the test_accuracy = 0.8788774002954209\n",
      "\n",
      "for max depth = 7 the train_accuracy = 0.913343180699163 and the test_accuracy = 0.8601674052191038\n",
      "\n",
      "for max depth = 8 the train_accuracy = 0.9218775644181848 and the test_accuracy = 0.8513047759724274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Your code here ####\n",
    "\n",
    "test_accuracy=[]\n",
    "train_accuracy =[]\n",
    "best_depth = 0\n",
    "best_accuracy = 0\n",
    "\n",
    "#create the list of accuracies for the train and the test\n",
    "for i in range(1,9):\n",
    "    tree = build_tree(X_train,calc_entropy,True, max_depth=i)\n",
    "    current_test_acc = calc_accuracy(tree,X_test)\n",
    "    current_train_acc = calc_accuracy(tree,X_train)\n",
    "    test_accuracy.append(current_test_acc)\n",
    "    train_accuracy.append(current_train_acc)\n",
    "    if current_test_acc > best_accuracy:\n",
    "        best_accuracy = current_test_acc\n",
    "        best_depth = i\n",
    "    print(f\"for max depth = {i} the train_accuracy = {current_train_acc} and the test_accuracy = {current_test_acc}\\n\" )\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "depth = list(range(1,9))\n",
    "plt.plot(depth, test_accuracy ,label = \"test\")\n",
    "plt.plot(depth,train_accuracy,label = \"train\")\n",
    "plt.scatter(x=best_depth, y=best_accuracy, linewidths= 2, label= \"best depth\", c='r')\n",
    "plt.legend()\n",
    "    \n",
    "    \n",
    "plt.xlabel(\"max_dapth\") \n",
    "plt.ylabel(\"accuracy\")  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Samples Split\n",
    "\n",
    "(15 points)\n",
    "\n",
    "Consider the following min_samples_split values: [1, 5, 10, 20, 50]. For each value, construct a tree and prune it according to the min_samples_split value = don't split a node if the number of sample in it is less or equal to the min_samples_split value. Next, calculate the training and testing accuracy.<br>\n",
    "On a single plot, draw the training and testing accuracy as a function of the min_samples_split. Mark the best result on the graph with red circle. (make sure that the x-axis ticks represent the values of min_samples_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_samples_split = 1 the train_accuracy = 0.971278516330215 and the test_accuracy = 0.8079763663220089\n",
      "\n",
      "for min_samples_split = 5 the train_accuracy = 0.9158050221565731 and the test_accuracy = 0.844411619891679\n",
      "\n",
      "for min_samples_split = 10 the train_accuracy = 0.9038240603971771 and the test_accuracy = 0.880354505169867\n",
      "\n",
      "for min_samples_split = 20 the train_accuracy = 0.9020187099950763 and the test_accuracy = 0.8906942392909897\n",
      "\n",
      "for min_samples_split = 50 the train_accuracy = 0.9016904644674216 and the test_accuracy = 0.8951255539143279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Your code here ####\n",
    "list_of_splits = [1, 5, 10, 20, 50]\n",
    "test_accuracy=[]\n",
    "train_accuracy =[]\n",
    "best_split = 0\n",
    "best_accuracy = 0\n",
    "\n",
    "#create the list of accuracies for the train and the test\n",
    "for i in list_of_splits:\n",
    "    tree = build_tree(X_train,calc_entropy,True, min_samples_split=i)\n",
    "    current_test_acc = calc_accuracy(tree,X_test)\n",
    "    current_train_acc = calc_accuracy(tree,X_train)\n",
    "    test_accuracy.append(current_test_acc)\n",
    "    train_accuracy.append(current_train_acc)\n",
    "    if current_test_acc > best_accuracy:\n",
    "        best_accuracy = current_test_acc\n",
    "        best_split = i\n",
    "    print(f\"for min_samples_split = {i} the train_accuracy = {current_train_acc} and the test_accuracy = {current_test_acc}\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_splits = [1, 5, 10, 20, 50]\n",
    "plt.plot(list_of_splits, test_accuracy ,label = \"test\")\n",
    "plt.plot(list_of_splits, train_accuracy,label = \"train\")\n",
    "plt.scatter(x=best_split, y=best_accuracy, linewidths= 2, label= \"best depth\", c='r')\n",
    "plt.legend()\n",
    "    \n",
    "    \n",
    "plt.xlabel(\"min_samples_split\") \n",
    "plt.ylabel(\"accuracy\")  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the best 2 trees:\n",
    "1. tree_max_depth - the best tree according to max_depth pruning\n",
    "1. tree_min_samples_split - the best tree according to min_samples_split pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your code here ####\n",
    "tree_max_depth = build_tree(X_train,calc_entropy,True, max_depth = 4)\n",
    "tree_min_sample_split = build_tree(X_train,calc_entropy,True,min_samples_split = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Nodes\n",
    "\n",
    "(5 points)\n",
    "\n",
    "Complete the function counts_nodes and print the number of nodes in each tree and print the number of nodes of the two trees above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes(node):\n",
    "    \"\"\"\n",
    "    Count the number of node in a given tree\n",
    " \n",
    "    Input:\n",
    "    - node: a node in the decision tree.\n",
    " \n",
    "    Output: the number of node in the tree.\n",
    "    \"\"\"\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    return node.count_children()\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes in tree_max_depth is 155\n",
      "The number of nodes in tree_min_sample_split is 317\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of nodes in tree_max_depth is {count_nodes(tree_max_depth)}\")\n",
    "print(f\"The number of nodes in tree_min_sample_split is {count_nodes(tree_min_sample_split)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the tree\n",
    "\n",
    "Complete the function `print_tree`. Your tree should be visualized clearly. You can use the following example as a reference:\n",
    "```\n",
    "[ROOT, feature=X0],\n",
    "  [X0=a, feature=X2]\n",
    "    [X2=c, leaf]: [{1.0: 10}]\n",
    "    [X2=d, leaf]: [{0.0: 10}]\n",
    "  [X0=y, feature=X5], \n",
    "    [X5=a, leaf]: [{1.0: 5}]\n",
    "    [X5=s, leaf]: [{0.0: 10}]\n",
    "  [X0=e, leaf]: [{0.0: 25, 1.0: 50}]\n",
    "```\n",
    "In each brackets:\n",
    "* The first argument is the parent feature with the value that led to current node\n",
    "* The second argument is the selected feature of the current node\n",
    "* If the current node is a leaf, you need to print also the labels and their counts\n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuples_of_labels(node:DecisionNode):\n",
    "    vals, frequency = np.unique(node.data[:,-1], return_counts=True)\n",
    "    return list(zip(vals, frequency))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('e', 3154), ('p', 2939)]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(get_tuples_of_labels(tree_max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can change the function signeture\n",
    "def print_tree(node, parent_feature='ROOT'):\n",
    "    '''\n",
    "    prints the tree according to the example above\n",
    "\n",
    "    Input:\n",
    "    - node: a node in the decision tree\n",
    "\n",
    "    This function has no return value\n",
    "    '''\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    if len(node.children) > 0: # if node  is not a leaf print its value and proceed to its children\n",
    "        print(f\"{' '*node.current_depth}[{parent_feature}, feature = X{node.feature}],\")\n",
    "        for child_node in node.children:\n",
    "            print_tree(child_node, node.feature) #print each child\n",
    "    else:\n",
    "       print(f\"{' '*node.current_depth}[{parent_feature}, leaf]: [{get_tuples_of_labels(node)}]\") \n",
    "\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes in test_tree is 46 and its accuracy on the test set is 0.8931560807483998\n"
     ]
    }
   ],
   "source": [
    "#base on the following guidlines test_tree here has the best accuracy based on both pruning methods and limitations of node number \n",
    "test_tree = build_tree(X_train, calc_entropy, gain_ratio=True, min_samples_split=225, max_depth=4)\n",
    "print(f\"The number of nodes in test_tree is {count_nodes(test_tree)} and its accuracy on the test set is {calc_accuracy(test_tree, X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the tree with the best test accuracy and with less than 50 nodes (from the two pruning methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROOT, feature = X4],\n",
      " [4, feature = X2],\n",
      "  [2, leaf]: [[('e', 33), ('p', 5)]]\n",
      "  [2, leaf]: [[('e', 107), ('p', 7)]]\n",
      "  [2, leaf]: [[('e', 133), ('p', 19)]]\n",
      " [4, leaf]: [[('e', 10), ('p', 137)]]\n",
      " [4, feature = X10],\n",
      "  [10, leaf]: [[('e', 14), ('p', 91)]]\n",
      "  [10, feature = X11],\n",
      "   [11, feature = X7],\n",
      "    [7, leaf]: [[('e', 112), ('p', 854)]]\n",
      "    [7, leaf]: [[('e', 6), ('p', 97)]]\n",
      "   [11, leaf]: [[('e', 16), ('p', 86)]]\n",
      "  [10, feature = X19],\n",
      "   [19, leaf]: [[('e', 2), ('p', 55)]]\n",
      "   [19, feature = X11],\n",
      "    [11, leaf]: [[('e', 4), ('p', 24)]]\n",
      "    [11, leaf]: [[('e', 6), ('p', 107)]]\n",
      "    [11, leaf]: [[('e', 10), ('p', 124)]]\n",
      " [4, leaf]: [[('e', 272), ('p', 27)]]\n",
      " [4, leaf]: [[('e', 2), ('p', 25)]]\n",
      " [4, feature = X7],\n",
      "  [7, feature = X18],\n",
      "   [18, leaf]: [[('e', 34), ('p', 2)]]\n",
      "   [18, feature = X11],\n",
      "    [11, leaf]: [[('e', 126), ('p', 19)]]\n",
      "    [11, leaf]: [[('e', 717), ('p', 74)]]\n",
      "   [18, feature = X15],\n",
      "    [15, leaf]: [[('e', 14), ('p', 4)]]\n",
      "    [15, leaf]: [[('e', 18), ('p', 1)]]\n",
      "    [15, leaf]: [[('e', 850), ('p', 100)]]\n",
      "   [18, leaf]: [[('e', 28), ('p', 4)]]\n",
      "   [18, leaf]: [[('e', 6), ('p', 46)]]\n",
      "   [18, feature = X13],\n",
      "    [13, leaf]: [[('e', 62), ('p', 9)]]\n",
      "    [13, leaf]: [[('e', 12), ('p', 2)]]\n",
      "    [13, leaf]: [[('e', 295), ('p', 22)]]\n",
      "   [18, leaf]: [[('e', 35), ('p', 3)]]\n",
      "  [7, leaf]: [[('e', 135), ('p', 58)]]\n",
      " [4, leaf]: [[('e', 8), ('p', 175)]]\n",
      " [4, feature = X13],\n",
      "  [13, leaf]: [[('e', 12), ('p', 190)]]\n",
      "  [13, leaf]: [[('e', 26), ('p', 190)]]\n",
      " [4, feature = X1],\n",
      "  [1, leaf]: [[('e', 18), ('p', 194)]]\n",
      "  [1, leaf]: [[('e', 31), ('p', 188)]]\n"
     ]
    }
   ],
   "source": [
    "#### Your code here ####\n",
    "print_tree(test_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
